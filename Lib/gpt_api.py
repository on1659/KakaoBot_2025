import os
import openai
import json
import time
from datetime import datetime, timedelta
from pathlib import Path

from . import json_data_manager  # ê°™ì€ íŒ¨í‚¤ì§€ ë‚´ ëª¨ë“ˆë¡œ ê°€ì •
from . import dataManager  # ê°™ì€ íŒ¨í‚¤ì§€ ë‚´ ëª¨ë“ˆë¡œ ê°€ì •

# 1) OpenAI API Key ì„¤ì •
openai.api_key = os.environ.get("OPENAI_API_KEY")
GPT_MAX_TOKEN = int(dataManager.GPT_MAX_TOKEN)

# API ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ íŒŒì¼ ê²½ë¡œ
USAGE_LOG_FILE = Path(__file__).parent.parent / "config" / "api_usage.json"

def load_usage_data():
    """API ì‚¬ìš©ëŸ‰ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    if USAGE_LOG_FILE.exists():
        try:
            with open(USAGE_LOG_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (json.JSONDecodeError, FileNotFoundError):
            pass
    return {
        "daily_usage": {},
        "total_requests": 0,
        "last_reset": datetime.now().strftime("%Y-%m-%d")
    }

def save_usage_data(data):
    """API ì‚¬ìš©ëŸ‰ ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        with open(USAGE_LOG_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"ì‚¬ìš©ëŸ‰ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")

def log_api_usage(model_name, prompt_length, response_length):
    """API ì‚¬ìš©ëŸ‰ì„ ë¡œê¹…í•©ë‹ˆë‹¤."""
    data = load_usage_data()
    today = datetime.now().strftime("%Y-%m-%d")
    
    # ì¼ì¼ ì‚¬ìš©ëŸ‰ ì´ˆê¸°í™” (ìƒˆë¡œìš´ ë‚ ì´ë©´)
    if data["last_reset"] != today:
        data["daily_usage"] = {}
        data["last_reset"] = today
    
    # ì˜¤ëŠ˜ ì‚¬ìš©ëŸ‰ ì—…ë°ì´íŠ¸
    if today not in data["daily_usage"]:
        data["daily_usage"][today] = {
            "requests": 0,
            "total_tokens": 0,
            "models": {}
        }
    
    data["daily_usage"][today]["requests"] += 1
    data["daily_usage"][today]["total_tokens"] += prompt_length + response_length
    data["total_requests"] += 1
    
    if model_name not in data["daily_usage"][today]["models"]:
        data["daily_usage"][today]["models"][model_name] = 0
    data["daily_usage"][today]["models"][model_name] += 1
    
    save_usage_data(data)

def get_usage_summary():
    """API ì‚¬ìš©ëŸ‰ ìš”ì•½ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    data = load_usage_data()
    today = datetime.now().strftime("%Y-%m-%d")
    
    if today in data["daily_usage"]:
        today_usage = data["daily_usage"][today]
        summary = f"ğŸ“Š API ì‚¬ìš©ëŸ‰ í˜„í™©\n"
        summary += f"ì˜¤ëŠ˜ ìš”ì²­ ìˆ˜: {today_usage['requests']}íšŒ\n"
        summary += f"ì˜¤ëŠ˜ í† í° ìˆ˜: {today_usage['total_tokens']:,}ê°œ\n"
        summary += f"ì´ ìš”ì²­ ìˆ˜: {data['total_requests']:,}íšŒ\n\n"
        
        if today_usage["models"]:
            summary += "ì‚¬ìš©ëœ ëª¨ë¸:\n"
            for model, count in today_usage["models"].items():
                summary += f"- {model}: {count}íšŒ\n"
        
        return summary
    else:
        return "ğŸ“Š API ì‚¬ìš©ëŸ‰ í˜„í™©\nì˜¤ëŠ˜ì€ ì•„ì§ APIë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."


def getData(opentalk_name: str, chat_command: str, user_prompt: str):
    """
    ì±„íŒ…ë°© ì´ë¦„(opentalk_name)ê³¼ ëª…ë ¹ì–´(chat_command), ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸(user_prompt)ë¥¼ ë°›ì•„
    DB/JSONì—ì„œ GPT ëª¨ë¸ì„ ì¡°íšŒí•œ í›„ ask_gpt í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ (ì‘ë‹µ, ë©”ì‹œì§€íƒ€ì…)ì„ ë°˜í™˜.
    """
    # JSONì—ì„œ êº¼ë‚¸ ëª¨ë¸ ì´ë¦„ì´ None ì´ë©´ ì„¤ì • íŒŒì¼ì˜ ê¸°ë³¸ê°’ ì‚¬ìš©
    model_name = json_data_manager.get_chatroom_data(opentalk_name, "gpt_model") or dataManager.GPT_DEFAULT_MODEL
    return ask_gpt(user_prompt, model_name)

def ask_gpt(prompt: str, model_name: str = None):
    """
    ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸(prompt)ì™€ ëª¨ë¸ ì´ë¦„(model_name)ì„ ë°›ì•„,
    OpenAI Chat APIë¥¼ í˜¸ì¶œ í›„ (ì‘ë‹µë¬¸ìì—´, "text") ë¥¼ ë°˜í™˜.
    """
    # model_nameì´ Noneì´ë©´ ì„¤ì • íŒŒì¼ì˜ ê¸°ë³¸ê°’ ì‚¬ìš©
    if model_name is None:
        model_name = dataManager.GPT_DEFAULT_MODEL
    
    # ë‹µë³€ ê¸¸ì´ ì œí•œ ë¬¸êµ¬ë¥¼ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
    prompt_with_limit = f"{prompt}\n\n{dataManager.GPT_ANSWER_LENGTH_LIMIT}"
    
    try:
        # prompt = f"{prompt}\n\në‹µë³€ì€ ë°˜ë“œì‹œ {GPT_MAX_TOKEN} í† í°ë³´ë‹¤ ì§§ê²Œ í•´ì¤˜."
        # API í˜¸ì¶œ ì‹œë„ (temperature ì˜¤ë¥˜ ì‹œ ìë™ìœ¼ë¡œ 1.0ìœ¼ë¡œ ì¬ì‹œë„)
        resp = None
        
        # gpt-5-nanoëŠ” temperature=1.0ë§Œ ì§€ì›í•˜ë©°, max_completion_tokensë¥¼ 200ìœ¼ë¡œ ì„¤ì •
        if "gpt-5-nano" in model_name:
            # gpt-5-nanoëŠ” í…ŒìŠ¤íŠ¸ì—ì„œ ì„±ê³µí•œ ì„¤ì •ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            resp = openai.chat.completions.create(
                model = model_name,
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user",   "content": prompt_with_limit}
                ],
                temperature=1.0,
                max_completion_tokens=1000,
                reasoning_effort="minimal"
            )
            
            # gpt-5-nanoê°€ ë¹ˆ ì‘ë‹µì„ ë°˜í™˜í•˜ëŠ” ê²½ìš° gpt-4o-minië¡œ fallback
            if resp.choices[0].message.content is None or resp.choices[0].message.content.strip() == "":
                print(f"gpt-5-nanoê°€ ë¹ˆ ì‘ë‹µì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤. gpt-4o-minië¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                resp = openai.chat.completions.create(
                    model = "gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": "You are a helpful assistant."},
                        {"role": "user",   "content": prompt_with_limit}
                    ],
                    temperature=0.7,
                    max_completion_tokens=GPT_MAX_TOKEN,
                )
        else:
            # ë‹¤ë¥¸ ëª¨ë¸ë“¤ì€ ê¸°ì¡´ ë¡œì§ ì‚¬ìš©
            temp_values = [0.7, 1.0]  # ë¨¼ì € 0.7 ì‹œë„, ì‹¤íŒ¨í•˜ë©´ 1.0 ì‹œë„
            max_completion_tokens_to_use = GPT_MAX_TOKEN
            
            for temp_value in temp_values:
                try:
                    resp = openai.chat.completions.create(
                        model = model_name,
                        messages=[
                            {"role": "system", "content": "You are a helpful assistant."},
                            {"role": "user",   "content": prompt_with_limit}
                        ],
                        temperature=temp_value,
                        max_completion_tokens = max_completion_tokens_to_use,
                    )
                    break  # ì„±ê³µí•˜ë©´ ë£¨í”„ ì¢…ë£Œ
                except openai.APIError as e:
                    if "temperature" in str(e) and temp_value == 0.7:
                        # temperature ì˜¤ë¥˜ì´ê³  0.7ì„ ì‹œë„í•œ ê²½ìš°, 1.0ìœ¼ë¡œ ì¬ì‹œë„
                        continue
                    else:
                        # ë‹¤ë¥¸ ì˜¤ë¥˜ì´ê±°ë‚˜ ì´ë¯¸ 1.0ì„ ì‹œë„í•œ ê²½ìš°, ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ë°œìƒ
                        raise e
        
        if resp is None:
            raise Exception("API í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        # openai>=1.0.0 ì—ì„œëŠ” resp.choices[0].message.content
        if not resp.choices or len(resp.choices) == 0:
            raise Exception("API ì‘ë‹µì— choicesê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        answer = resp.choices[0].message.content
        if answer is not None:
            answer = answer.strip()
        else:
            answer = ""
        
        # API ì‚¬ìš©ëŸ‰ ë¡œê¹…
        try:
            log_api_usage(model_name, len(prompt), len(answer))
        except Exception as e:
            print(f"ì‚¬ìš©ëŸ‰ ë¡œê¹… ì‹¤íŒ¨: {e}")
        
        max_chars = GPT_MAX_TOKEN * 2  # í•œê¸€ ê¸°ì¤€ ëŒ€ëµì¹˜
        show_limit_notice = len(answer) >= int(max_chars * 0.9)
        if show_limit_notice:
            text = f'ì§ˆë¬¸í•˜ì‹  "{prompt}"ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤. ìµœëŒ€ ì•½ {max_chars}ìê¹Œì§€ ë‹µë³€ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n- {answer}'
        else:
            text = f'ì§ˆë¬¸í•˜ì‹  "{prompt}"ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤.\n- {answer}'
        return text, "text"
    
    except openai.RateLimitError as e:
        error_msg = "OpenAI API í• ë‹¹ëŸ‰ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ê±°ë‚˜ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        print(f"RateLimitError: {e}")
        return error_msg, "text"
    
    except openai.APIError as e:
        error_msg = f"OpenAI API ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        print(f"APIError: {e}")
        return error_msg, "text"
    
    except Exception as e:
        error_msg = f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        print(f"Unexpected error: {e}")
        return error_msg, "text"


def update_chatroom_gptmodele(chatroom_name, chat_command, mdole_string, file_path=None):
    """
    ì±„íŒ…ë°©ì˜ gpt_model ê°’ì„ mdole_stringìœ¼ë¡œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    file_pathê°€ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ ê²½ë¡œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ì´ë©´ ì•ˆë‚´ ë©”ì‹œì§€ì™€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if file_path is None:
        file_path = json_data_manager.CHATROOM_FILE_PATH

    available_models = dataManager.GPT_MODEL_LIST
    if mdole_string not in available_models:
        if not available_models:
            return "ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API Key ë˜ëŠ” ë„¤íŠ¸ì›Œí¬ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.", "text"
        msg = (
            f"í•´ë‹¹ ëª¨ë¸ì€ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì§€ì› ê°€ëŠ¥í•œ ë¦¬ìŠ¤íŠ¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\n"
            f"ì§€ì› ê°€ëŠ¥í•œ ëª¨ë¸:\n" + "\n".join(f"- {mid}" for mid in available_models)
        )
        return msg, "text"

    json_data_manager.update_chatroom_data(chatroom_name, "gpt_model", mdole_string, file_path)
    return f"ëª¨ë¸ì´ '{mdole_string}'(ìœ¼)ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.", "text"

def chatroom_gpt_model(opentalk_name, chat_command, message):
    """
    í˜„ì¬ ì±„íŒ…ë°©ì—ì„œ ì‚¬ìš© ì¤‘ì¸ GPT ëª¨ë¸ì„ ì¡°íšŒí•˜ëŠ” í•¨ìˆ˜
    """
    current_model = json_data_manager.get_chatroom_data(opentalk_name, "gpt_model")
    if current_model:
        return f"í˜„ì¬ ì±„íŒ…ë°©ì—ì„œ ì‚¬ìš© ì¤‘ì¸ GPT ëª¨ë¸: {current_model}", "text"
    else:
        return f"í˜„ì¬ ì±„íŒ…ë°©ì˜ GPT ëª¨ë¸ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "text"

def api_usage_status(opentalk_name, chat_command, message):
    """
    API ì‚¬ìš©ëŸ‰ í˜„í™©ì„ ì¡°íšŒí•˜ëŠ” í•¨ìˆ˜
    """
    return get_usage_summary(), "text"